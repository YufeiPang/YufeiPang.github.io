<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>时间序列分析--ARIMA模型</title>
    <link href="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/"/>
    <url>/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="习题5-3"><a href="#习题5-3" class="headerlink" title="习题5.3"></a>习题5.3</h1><pre><code class="hljs SAS"><span class="hljs-meta">libname</span> datafile <span class="hljs-string">&#x27;d:\SASHome\myfile&#x27;</span>;<span class="hljs-keyword">data </span>datafile.example5_1;<span class="hljs-meta">input</span> sheep@@;y<span class="hljs-meta">=dif(</span>sheep);time<span class="hljs-meta">=intnx(</span><span class="hljs-string">&#x27;year&#x27;</span>,<span class="hljs-string">&#x27;01Sep1867&#x27;</span>d,<span class="hljs-literal">_n_</span>-1);<span class="hljs-meta">format</span> time YEAR.;<span class="hljs-emphasis">cards;</span><span class="hljs-emphasis">2203 2360 2254 2165 2024 2078 2214 2292 2207 2119 2119 2137 2132 1955 1785 1747 1818 1909 1958 1892 1919 1853 1868 1991 2111 2119 1991 1859 1856 1924 1892 1916 1968 1928 1898 1850 1841 1824 1823 1843 1880 1968 2029 1996 1933 1805 1713 1726 1752 1795 1717 1648 1512 1338 1383 1344 1384 1484 1597 1686 1707 1640 1611 1632 1775 1850 1809 1653 1648 1665 1627 1791</span><span class="hljs-emphasis">proc gplot data=datafile.example5_1;</span><span class="hljs-emphasis">plot sheep*time=1 y*time=2/overlay;</span><span class="hljs-emphasis">symbol1 c=red v=star i=join;</span><span class="hljs-emphasis">symbol2 c=black v=diamond i=join;</span><span class="hljs-emphasis">run;</span><span class="hljs-emphasis">proc arima data=datafile.example5_1;</span><span class="hljs-emphasis">identify var=y stationarity=(adf) minic p=(0:5) q=(0:5);</span><span class="hljs-emphasis">estimate p=2 noint;</span><span class="hljs-emphasis">run;</span><span class="hljs-emphasis">forecast lead=7 id=time out=results5_1;</span><span class="hljs-emphasis">run;</span><span class="hljs-emphasis">proc gplot data=results5_1;</span><span class="hljs-emphasis">plot y*time=1 forecast*time=2 l95*time=3 u95*time=3/overlay;</span><span class="hljs-emphasis">symbol1 c=black v=star i=none;</span><span class="hljs-emphasis">symbol2 c=red v=none i=join;</span><span class="hljs-emphasis">symbol3 c=green v=none i=join l=32;</span><span class="hljs-emphasis">run;</span></code></pre><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/1.png" class=""><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/2.png" class=""><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/3.png" class=""><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/4.png" class=""><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/5.png" class=""><img src="/2020/12/19/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-ARIMA%E6%A8%A1%E5%9E%8B/6.png" class="">]]></content>
    
    
    
    <tags>
      
      <tag>SAS 时间序列分析 ARIMA模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言之多重共线性与岭回归</title>
    <link href="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
    <url>/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1 id="习题7-6"><a href="#习题7-6" class="headerlink" title="习题7.6"></a>习题7.6</h1><h3 id="1-导入数据"><a href="#1-导入数据" class="headerlink" title="1.导入数据"></a>1.导入数据</h3><pre><code class="hljs R">data7.6&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/Dell/Desktop/7.6.csv&quot;</span>)data7.6=data.frame(matrix(unlist(data7.6),nrow=<span class="hljs-number">25</span>))colnames(data7.6)=<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;y&quot;</span>,<span class="hljs-string">&quot;x1&quot;</span>,<span class="hljs-string">&quot;x2&quot;</span>,<span class="hljs-string">&quot;x3&quot;</span>,<span class="hljs-string">&quot;x4&quot;</span>)<span class="hljs-comment">#给dataframe重命名</span>data7.6</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/1.png" class=""><h3 id="2-计算简单相关系数"><a href="#2-计算简单相关系数" class="headerlink" title="2.计算简单相关系数"></a>2.计算简单相关系数</h3><pre><code class="hljs R"><span class="hljs-comment">#计算简单相关系数</span>cor(data7.6)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/2.png" class=""><p><strong>结果分析：$y$与四个自变量的相关系数分别为$0.84,0.72,0.70,0.51$，说明$y$与其余4个变量是显著线性相关的。同时也可以看出自变量之间也存在一定的线性相关性。</strong></p><h3 id="3-建立线性回归方程"><a href="#3-建立线性回归方程" class="headerlink" title="3.建立线性回归方程"></a>3.建立线性回归方程</h3><pre><code class="hljs R"><span class="hljs-comment">#标准化</span>newdata=scale(data7.6,center=<span class="hljs-literal">TRUE</span>,scale=<span class="hljs-literal">TRUE</span>)data7.6=data.frame(matrix(newdata,nrow=<span class="hljs-number">25</span>))colnames(data7.6)=<span class="hljs-built_in">c</span>(<span class="hljs-string">&quot;y&quot;</span>,<span class="hljs-string">&quot;x1&quot;</span>,<span class="hljs-string">&quot;x2&quot;</span>,<span class="hljs-string">&quot;x3&quot;</span>,<span class="hljs-string">&quot;x4&quot;</span>)attach(data7.6)<span class="hljs-comment">#建立线性回归模型</span>lm1&lt;-lm(y~.,data=data7.6)summary(lm1)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/3.png" class=""><p><strong>结果分析：回归方程中，自变量$x_2,x_3,x_4$未通过$t$检验，说明回归系数$\beta_2,\beta_3,\beta_4$不显著。与此同时，从实际意义出发，$x_4$的回归系数$\beta_4$不能是负数。综上，原始方程所得的回归系数不合理。</strong></p><h3 id="4-诊断多重共线性"><a href="#4-诊断多重共线性" class="headerlink" title="4.诊断多重共线性"></a>4.诊断多重共线性</h3><h4 id="（1）方差扩大因子法"><a href="#（1）方差扩大因子法" class="headerlink" title="（1）方差扩大因子法"></a>（1）方差扩大因子法</h4><pre><code class="hljs R"><span class="hljs-comment">#诊断多重共线性</span><span class="hljs-comment">#法一：方差扩大因子法</span>library(car)vif_result=vif(lm1)mean(vif_result)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/4.png" class=""><p><strong>结果分析：方差扩大因子的均值大于$1$，故可推测，自变量间可能存在轻微的多重共线性。</strong></p><h4 id="（2）特征根判别法"><a href="#（2）特征根判别法" class="headerlink" title="（2）特征根判别法"></a>（2）特征根判别法</h4><pre><code class="hljs R"><span class="hljs-comment">#法二：特征根判别法</span><span class="hljs-comment">#计算条件数</span>XX=cor(data7.6[,<span class="hljs-number">2</span>:<span class="hljs-number">5</span>])kappa(XX,exact=<span class="hljs-literal">TRUE</span>)<span class="hljs-comment">#计算矩阵的特征值和响应的特征向量——找出哪些变量是多重共线性的</span>eigen(XX)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/5.png" class=""><p><strong>结果分析：条件数$k=23.236$，由于$10&lt;k&lt;100$，故可以判断设计矩阵$X$——即自变量间存在较强的多重共线性。而在返回的四个特征值中$0.1322467$接近$0$，故设计矩阵$X$中至少有一个多重共线性关系，其对应的系数向量即为$(0.822,-0.199,-0.490,-0.209)$。</strong></p><h4 id="（3）直观判断法"><a href="#（3）直观判断法" class="headerlink" title="（3）直观判断法"></a>（3）直观判断法</h4><div class="table-container"><table><thead><tr><th>综合第2，3部分的结果可以发现：</th></tr></thead><tbody><tr><td>(i.)$y$与四个自变量的相关系数分别为$0.84,0.72,0.70,0.51$，说明$y$与其余4个变量是显著线性相关的。但在利用最小二乘估计建立的回归方程中，自变量$x_2,x_3,x_4$未通过显著性检验。</td></tr><tr><td>(ii.)在自变量的相关矩阵中，部分自变量间的相关系数较大。</td></tr><tr><td>(iii.)大部分与因变量$y$相关度较高的——重要的自变量，其对应回归系数的标准误差较大。</td></tr><tr><td>(iv.)从实际意义出发，$x_4$的回归系数$\beta_4$不能是负数，这与定性分析的结果相反。</td></tr></tbody></table></div><h3 id="5-消除多重共线性"><a href="#5-消除多重共线性" class="headerlink" title="5.消除多重共线性"></a>5.消除多重共线性</h3><h4 id="（1）剔除一些不重要的解释变量"><a href="#（1）剔除一些不重要的解释变量" class="headerlink" title="（1）剔除一些不重要的解释变量"></a>（1）剔除一些不重要的解释变量</h4><h5 id="a-后退法"><a href="#a-后退法" class="headerlink" title="a.后退法"></a>a.后退法</h5><pre><code class="hljs R"><span class="hljs-comment">#使用后退法选择自变量</span>lm7.6.back=step(lm1,direction=<span class="hljs-string">&quot;backward&quot;</span>)summary(lm7.6.back)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/6.png" class=""><h5 id="b-逐步回归法"><a href="#b-逐步回归法" class="headerlink" title="b.逐步回归法"></a>b.逐步回归法</h5><pre><code class="hljs R"><span class="hljs-comment">#使用逐步回归法选择自变量</span>lm7.6.step=step(lm1,direction=<span class="hljs-string">&quot;both&quot;</span>)summary(lm7.6.step)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/7.png" class=""><h5 id="c-岭迹分析"><a href="#c-岭迹分析" class="headerlink" title="c.岭迹分析"></a>c.岭迹分析</h5><pre><code class="hljs R"><span class="hljs-comment">#建立岭回归</span>library(MASS)lm7.6.ridge=lm.ridge(y~.,data=data7.6,lambda=seq(<span class="hljs-number">0</span>,<span class="hljs-number">100.0</span>,<span class="hljs-number">0.1</span>))<span class="hljs-comment">#绘制岭迹图</span>plot(lm.ridge(y~.,data=data7.6,lambda=seq(<span class="hljs-number">0</span>,<span class="hljs-number">100.0</span>,<span class="hljs-number">0.1</span>)))</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/8.png" class=""><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/9.png" class=""><div class="table-container"><table><thead><tr><th><strong>结果分析：</strong></th></tr></thead><tbody><tr><td>由岭迹图可知，$x_3$的标准化岭回归系数比较稳定且绝对值很小，故可予以剔除。这与后退法和逐步回归法的结果一致，三种方法大体上都保留了$x_1,x_2,x_4$三个自变量建立回归方程。</td></tr><tr><td>但在利用最小二乘估计建立的回归方程中，自变量$x_2,x_4$未通过显著性检验。且大部分与因变量$y$相关度较高的——重要的自变量，其对应回归系数的标准误差较大。而从实际意义出发，$x_4$的回归系数$\beta_4$不能是负数，这与定性分析的结果相反。</td></tr><tr><td><strong>综上，利用剔除一些不重要的解释变量来消除多重共线性的效果较差。</strong></td></tr></tbody></table></div><h4 id="（2）增大样本量"><a href="#（2）增大样本量" class="headerlink" title="（2）增大样本量"></a>（2）增大样本量</h4><p>由于无法得到新的样本数据，该方法在本文体重是不现实的，故不进行展开讨论。</p><h4 id="（3）回归系数的有偏估计——岭回归"><a href="#（3）回归系数的有偏估计——岭回归" class="headerlink" title="（3）回归系数的有偏估计——岭回归"></a>（3）回归系数的有偏估计——岭回归</h4><pre><code class="hljs R"><span class="hljs-comment">#建立岭回归</span>library(MASS)lm7.6.ridge=lm.ridge(y~.,data=data7.6,lambda=seq(<span class="hljs-number">0</span>,<span class="hljs-number">100.0</span>,<span class="hljs-number">0.1</span>))<span class="hljs-comment">#绘制岭迹图</span>plot(lm.ridge(y~.,data=data7.6,lambda=seq(<span class="hljs-number">0</span>,<span class="hljs-number">100.0</span>,<span class="hljs-number">0.1</span>)))<span class="hljs-comment">#选择岭参数</span>select(lm.ridge(y~.,data=data7.6,lambda=seq(<span class="hljs-number">0</span>,<span class="hljs-number">100.0</span>,<span class="hljs-number">0.01</span>)))detach(data7.6)</code></pre><img src="/2020/12/14/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92/10.png" class=""><p><strong>结果分析：建立岭回归估计模型，利用广义交叉验证优选的$k$值为$0.84$。</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>R语言 多重共线性 岭回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>用Python批量合并Word文档</title>
    <link href="/2020/12/07/%E7%94%A8Python%E6%89%B9%E9%87%8F%E5%90%88%E5%B9%B6Word%E6%96%87%E6%A1%A3/"/>
    <url>/2020/12/07/%E7%94%A8Python%E6%89%B9%E9%87%8F%E5%90%88%E5%B9%B6Word%E6%96%87%E6%A1%A3/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs python"><span class="hljs-comment">#导库用以获取目录路径</span><span class="hljs-keyword">import</span> os<span class="hljs-keyword">import</span> win32com.client <span class="hljs-keyword">as</span>  win32<span class="hljs-comment">#启动word对象应用</span>word=win32.gencache.EnsureDispatch(<span class="hljs-string">&#x27;Word.Application&#x27;</span>)<span class="hljs-comment">#需要合并的文件所在路径</span>word.Visible = <span class="hljs-literal">False</span>path=<span class="hljs-string">r&#x27;C:\Users\DELL\Desktop\数据分析题目&#x27;</span><span class="hljs-comment">#如果出现错误-2147023174, &#x27;RPC 服务器不可用。&#x27;, None, None</span><span class="hljs-comment">#打开控制面板——管理工具——服务——分别找到“DCOM Server Process Launcher”“RPC Endpoint Mapper”“Windows Time”</span><span class="hljs-comment">#将上述三者全部启动（为了方便后续操作建议打开属性——设置为自启动）</span><span class="hljs-comment">#启动后关闭编译器和程序全部重启</span><span class="hljs-comment">#获取目录下所有文件的路径</span>files = []filename = os.listdir(path)<span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filename:    filename = os.path.join(path,filename)    files.append(filename)    <span class="hljs-comment">#新建空的word文档</span>output = word.Documents.Add()<span class="hljs-comment">#拼接文档</span><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:    output.Application.Selection.InsertFile(file)    <span class="hljs-comment">#获取合并后文档的内容</span>doc = output.Range(output.Content.Start, output.Content.End)<span class="hljs-comment">#把汇总文件保存到指定路径</span>output.SaveAs(<span class="hljs-string">r&#x27;C:\Users\DELL\Desktop\数据分析题目\汇总.docx&#x27;</span>)<span class="hljs-comment">#关闭</span>output.Close()</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>Python 智能办公</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言之自变量选择-2</title>
    <link href="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/"/>
    <url>/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/</url>
    
    <content type="html"><![CDATA[<h1 id="习题5-10"><a href="#习题5-10" class="headerlink" title="习题5.10"></a>习题5.10</h1><h3 id="1-导入数据"><a href="#1-导入数据" class="headerlink" title="1.导入数据"></a>1.导入数据</h3><pre><code class="hljs R"><span class="hljs-comment">#导入数据</span>data5.10&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/5.10.csv&quot;</span>)data5.10=data.frame(matrix(unlist(data5.10),nrow=<span class="hljs-number">16</span>))<span class="hljs-comment">#将数据标准化</span>newdata=scale(data5.10,center=<span class="hljs-literal">TRUE</span>,scale=<span class="hljs-literal">TRUE</span>)data5.10=data.frame(matrix(newdata,nrow=<span class="hljs-number">16</span>))y=data5.10[[<span class="hljs-number">7</span>]]attach(data5.10)</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/1.png" class=""><h3 id="2-最小二乘估计建立不含自变量x1的选模型"><a href="#2-最小二乘估计建立不含自变量x1的选模型" class="headerlink" title="2.最小二乘估计建立不含自变量x1的选模型"></a>2.最小二乘估计建立不含自变量x1的选模型</h3><pre><code class="hljs R">lm1&lt;-lm(y~X2+X3+X4+X5+X6,data=data5.10)summary(lm1)</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/2.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>回归方程为：$\hat{y}=0.6773x_2+0.7817x_3-1.156x_4+0.05044x_5-0.8988x_6$。</td></tr></tbody></table></div><h3 id="3-自变量选择"><a href="#3-自变量选择" class="headerlink" title="3.自变量选择"></a>3.自变量选择</h3><h4 id="1-所有子集回归"><a href="#1-所有子集回归" class="headerlink" title="(1)所有子集回归"></a>(1)所有子集回归</h4><h5 id="i-准则一：调整的复决定系数-R-2-alpha"><a href="#i-准则一：调整的复决定系数-R-2-alpha" class="headerlink" title="(i)准则一：调整的复决定系数$ R^2_\alpha$"></a>(i)准则一：调整的复决定系数$ R^2_\alpha$</h5><pre><code class="hljs R">library(leaps)lm5.10.sub=regsubsets(y~X2+X3+X4+X5+X6,data=data5.10,really.big=<span class="hljs-built_in">T</span>)sub.res=summary(lm5.10.sub)<span class="hljs-comment">#调整的复决定系数R方</span>res.adjr2=data.frame(sub.res$outmat,adjr2=sub.res$adjr2)res.adjr2</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/3.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=4个自变量时，调整的复决定系数$ R^2_\alpha$达到最大值0.7593847，4个自变量分别是$x_2,x_3,x_4,x_6$。</td></tr></tbody></table></div><h5 id="ii-准则二：-C-p-统计量"><a href="#ii-准则二：-C-p-统计量" class="headerlink" title="(ii)准则二：$C_p$统计量"></a>(ii)准则二：$C_p$统计量</h5><pre><code class="hljs R"><span class="hljs-comment">#Cp统计量</span>res.Cp=data.frame(sub.res$outmat,Cp=sub.res$cp)res.Cp</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/4.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=4个自变量时，$C_p$统计量达到最小值4.009771，4个自变量分别是$x_2,x_3,x_4,x_6$。</td></tr></tbody></table></div><h5 id="iii-准则三：-BIC-信息量"><a href="#iii-准则三：-BIC-信息量" class="headerlink" title="(iii)准则三：$BIC$信息量"></a>(iii)准则三：$BIC$信息量</h5><pre><code class="hljs R"><span class="hljs-comment">#BIC信息量</span>res.BIC=data.frame(sub.res$outmat,BIC=sub.res$bic)res.BIC</code></pre> <img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/5.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=4个自变量时，$BIC$信息量达到最小值-13.8924312，4个自变量分别是$x_2,x_3,x_4,x_6$。</td></tr></tbody></table></div><p><strong>综上，在三种评判准则下，最优子集皆为$x_2,x_3,x_4,x_6$。</strong></p><h4 id="2-逐步回归"><a href="#2-逐步回归" class="headerlink" title="(2)逐步回归"></a>(2)逐步回归</h4><h5 id="i-前进法"><a href="#i-前进法" class="headerlink" title="(i)前进法"></a>(i)前进法</h5><pre><code class="hljs R"><span class="hljs-comment">#1.前进法</span>lmo5.10&lt;-lm(y~X2,data=data5.10)lm5.10.for&lt;-step(lmo5.10,scope=<span class="hljs-built_in">list</span>(upper=~X2+X3+X4+X5+X6,lower=~<span class="hljs-number">1</span>),direction=<span class="hljs-string">&quot;forward&quot;</span>)summary(lm5.10.for)</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/6.png" class=""><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/7.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，前进法依次引入变量$x_2,x_3,x_4,x_6$，最优回归模型为<strong>$\hat{y}=0.7057x_2+0.7598x_3-1.165x_4-0.9156x_6$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果优秀。</td></tr></tbody></table></div><h5 id="ii-后退法"><a href="#ii-后退法" class="headerlink" title="(ii)后退法"></a>(ii)后退法</h5><pre><code class="hljs R"><span class="hljs-comment">#2.后退法</span>lm5.10&lt;-lm(y~X2+X3+X4+X5+X6,data=data5.10)lm5.10.back&lt;-step(lm5.10,direction=<span class="hljs-string">&quot;backward&quot;</span>)summary(lm5.10.back)</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/8.png" class=""><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/9.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，后退法依次剔除变量$x_5$，最优回归模型为<strong>$\hat{y}=0.7057x_2+0.7598x_3-1.165x_4-0.9156x_6$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果良好。</td></tr></tbody></table></div><h5 id="iii-逐步回归法"><a href="#iii-逐步回归法" class="headerlink" title="(iii)逐步回归法"></a>(iii)逐步回归法</h5><pre><code class="hljs R"><span class="hljs-comment">#3.逐步回归法</span>lm5.10&lt;-lm(y~X2+X3+X4+X5+X6,data=data5.10)lm5.10.step&lt;-step(lm5.10,direction=<span class="hljs-string">&quot;both&quot;</span>)summary(lm5.10.step)detach(data5.10)</code></pre><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/10.png" class=""><img src="/2020/11/30/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-2/11.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，逐步回归法依次剔除变量$x_5$，最优回归模型为<strong>$\hat{y}=0.7057x_2+0.7598x_3-1.165x_4-0.9156x_6$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果良好。</td></tr></tbody></table></div><h3 id="4-结果分析"><a href="#4-结果分析" class="headerlink" title="4.结果分析"></a>4.结果分析</h3><div class="table-container"><table><thead><tr><th>调整的复决定系数$ R^2_\alpha$</th><th>$C_p$统计量</th><th>$BIC$信息量</th></tr></thead><tbody><tr><td>最大值0.7593847</td><td>最小值4.009771</td><td>最小值-13.8924312</td></tr><tr><td>$x_2,x_3,x_4,x_6$</td><td>$x_2,x_3,x_4,x_6$</td><td>$x_2,x_3,x_4,x_6$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>前进法</th><th>后退法</th><th>逐步回归法</th></tr></thead><tbody><tr><td>$x_2,x_3,x_4,x_6$</td><td>$x_2,x_3,x_4,x_6$</td><td>$x_2,x_3,x_4,x_6$</td></tr><tr><td>$R^2$=0.8235</td><td>$R^2$=0.8235</td><td>$R^2$=0.8235</td></tr><tr><td>$ R^2_\alpha$=0.7594</td><td>$ R^2_\alpha$=0.7594</td><td>$ R^2_\alpha$=0.7594</td></tr></tbody></table></div><p><strong>综上，最优子集为$x_2,x_3,x_4,x_6$，最优回归模型为$\hat{y}=0.7057x_2+0.7598x_3-1.165x_4-0.9156x_6$。</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>R语言 自变量选择 所有子集回归 逐步回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决Hexo博客MathJax公式渲染问题</title>
    <link href="/2020/11/28/%E8%A7%A3%E5%86%B3Hexo%E5%8D%9A%E5%AE%A2MathJax%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E9%97%AE%E9%A2%98/"/>
    <url>/2020/11/28/%E8%A7%A3%E5%86%B3Hexo%E5%8D%9A%E5%AE%A2MathJax%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="解决Hexo博客MathJax公式渲染问题"><a href="#解决Hexo博客MathJax公式渲染问题" class="headerlink" title="解决Hexo博客MathJax公式渲染问题"></a>解决Hexo博客MathJax公式渲染问题</h1><h3 id="1-安装渲染器"><a href="#1-安装渲染器" class="headerlink" title="1.安装渲染器"></a>1.安装渲染器</h3><p>以管理员身份打开cmd命令行进入博客目录，键入如下两行代码：</p><pre><code class="hljs php">cnpm uninstall hexo-renderer-marked --savecnpm install hexo-renderer-kramed --save</code></pre><h3 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2.修改配置文件"></a>2.修改配置文件</h3><p>在博客文件夹中，对应主题配置文件中<code>_config.yml</code>，找到<code>math(或mathjax)</code>【根据主题的不同，配置稍有差别，详情参考对应主题的帮助文档】，将其修改为<code>true</code>:</p><pre><code class="hljs yaml"><span class="hljs-attr">math:</span>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span></code></pre><h3 id="3-文章渲染标签"><a href="#3-文章渲染标签" class="headerlink" title="3.文章渲染标签"></a>3.文章渲染标签</h3><p>为加快渲染速度，渲染器只会在文章中有<code>math: true</code>或<code>math(或mathjax)</code>的文章中进行渲染。</p><pre><code class="hljs yaml"><span class="hljs-attr">title:</span> <span class="hljs-string">解决Hexo博客MathJax公式渲染问题</span><span class="hljs-attr">date:</span> <span class="hljs-number">2020-11-28 01:12:50</span><span class="hljs-attr">tags:</span> <span class="hljs-string">Hexo</span> <span class="hljs-string">博客优化</span><span class="hljs-attr">math:</span> <span class="hljs-literal">true</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo 博客优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言之自变量选择(1)</title>
    <link href="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/"/>
    <url>/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/</url>
    
    <content type="html"><![CDATA[<h1 id="习题5-9"><a href="#习题5-9" class="headerlink" title="习题5.9"></a>习题5.9</h1><h3 id="1-导入数据"><a href="#1-导入数据" class="headerlink" title="1.导入数据"></a>1.导入数据</h3><pre><code class="hljs R"><span class="hljs-comment">#导入数据</span>data5.9&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/5.9.csv&quot;</span>)data.frame(matrix(unlist(data5.9),nrow=<span class="hljs-number">21</span>))y=data5.9[[<span class="hljs-number">7</span>]]attach(data5.9)</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/1.png" class=""><h3 id="2-自变量选择"><a href="#2-自变量选择" class="headerlink" title="2.自变量选择"></a>2.自变量选择</h3><h4 id="1-所有子集回归"><a href="#1-所有子集回归" class="headerlink" title="(1)所有子集回归"></a>(1)所有子集回归</h4><h5 id="i-准则一：调整的复决定系数-R-2-alpha"><a href="#i-准则一：调整的复决定系数-R-2-alpha" class="headerlink" title="(i)准则一：调整的复决定系数$ R^2_\alpha$"></a>(i)准则一：调整的复决定系数$ R^2_\alpha$</h5><pre><code class="hljs R">library(leaps)lm5.9.sub=regsubsets(y~x1+x2+x3+x4+x5+x6,data=data5.9,really.big=<span class="hljs-built_in">T</span>)sub.res=summary(lm5.9.sub)<span class="hljs-comment">#调整的复决定系数R方</span>res.adjr2=data.frame(sub.res$outmat,adjr2=sub.res$adjr2)res.adjr2</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/2.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=3个自变量时，调整的复决定系数$ R^2_\alpha$达到最大值0.9951031，3个自变量分别是$x_1,x_2,x_5$。</td></tr></tbody></table></div><h5 id="ii-准则二：-C-p-统计量"><a href="#ii-准则二：-C-p-统计量" class="headerlink" title="(ii)准则二：$C_p$统计量"></a>(ii)准则二：$C_p$统计量</h5><pre><code class="hljs R"><span class="hljs-comment">#Cp统计量</span>res.Cp=data.frame(sub.res$outmat,Cp=sub.res$cp)res.Cp</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/3.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=3个自变量时，$C_p$统计量达到最小值2.490471，3个自变量分别是$x_1,x_2,x_5$。</td></tr></tbody></table></div><h5 id="iii-准则三：-BIC-信息量"><a href="#iii-准则三：-BIC-信息量" class="headerlink" title="(iii)准则三：$BIC$信息量"></a>(iii)准则三：$BIC$信息量</h5><pre><code class="hljs R"><span class="hljs-comment">#BIC信息量</span>res.BIC=data.frame(sub.res$outmat,BIC=sub.res$bic)res.BIC</code></pre> <img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/4.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，子集含有p=3个自变量时，$BIC$信息量达到最小值-102.93685，3个自变量分别是$x_1,x_2,x_5$。</td></tr></tbody></table></div><p><strong>综上，在三种评判准则下，最优子集皆为$x_1,x_2,x_5$。</strong></p><h4 id="2-逐步回归"><a href="#2-逐步回归" class="headerlink" title="(2)逐步回归"></a>(2)逐步回归</h4><h5 id="i-前进法"><a href="#i-前进法" class="headerlink" title="(i)前进法"></a>(i)前进法</h5><pre><code class="hljs R"><span class="hljs-comment">#1.前进法</span>lmo5.9&lt;-lm(y~<span class="hljs-number">1</span>,data=data5.9)lm5.9.for&lt;-step(lmo5.9,scope=<span class="hljs-built_in">list</span>(upper=~x1+x2+x3+x4+x5+x6,lower=~<span class="hljs-number">1</span>),direction=<span class="hljs-string">&quot;forward&quot;</span>)summary(lm5.9.for)</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/5.png" class=""><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/6.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，前进法依次引入变量$x_5,x_1,x_2$，最优回归模型为<strong>$\hat{y}=874.60731-0.61119x_1-0.35306x_2+0.63672x_5$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果优秀。</td></tr></tbody></table></div><h5 id="ii-后退法"><a href="#ii-后退法" class="headerlink" title="(ii)后退法"></a>(ii)后退法</h5><pre><code class="hljs R"><span class="hljs-comment">#2.后退法</span>lm5.9&lt;-lm(y~x1+x2+x3+x4+x5+x6,data=data5.9)<span class="hljs-comment">#全模型的第一种表示方式</span>lm5.9.back&lt;-step(lm5.9,direction=<span class="hljs-string">&quot;backward&quot;</span>)summary(lm5.9.back)</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/7.png" class=""><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/8.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，后退法依次剔除变量$x_4,x_3,x_6$，最优回归模型为<strong>$\hat{y}=874.60731-0.61119x_1-0.35306x_2+0.63672x_5$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果优秀。</td></tr></tbody></table></div><h5 id="iii-逐步回归法"><a href="#iii-逐步回归法" class="headerlink" title="(iii)逐步回归法"></a>(iii)逐步回归法</h5><pre><code class="hljs R"><span class="hljs-comment">#3.逐步回归法</span>lm5.9&lt;-lm(y~.,data=data5.9)<span class="hljs-comment">#全模型的第二种表示方式</span>lm5.9.step&lt;-step(lm5.9,direction=<span class="hljs-string">&quot;both&quot;</span>)summary(lm5.9.step)detach(data5.9)</code></pre><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/9.png" class=""><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/10.png" class=""><img src="/2020/11/28/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%87%AA%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9-1/11.png" class=""><div class="table-container"><table><thead><tr><th>结果分析：</th></tr></thead><tbody><tr><td>由输出结果可知，逐步回归法依次剔除变量$x_4,x_3,x_6$，最优回归模型为<strong>$\hat{y}=874.60731-0.61119x_1-0.35306x_2+0.63672x_5$</strong>，其中回归系数与回归方程均通过显著性检验，拟合效果优秀。</td></tr></tbody></table></div><h3 id="3-结果分析"><a href="#3-结果分析" class="headerlink" title="3.结果分析"></a>3.结果分析</h3><div class="table-container"><table><thead><tr><th>调整的复决定系数$ R^2_\alpha$</th><th>$C_p$统计量</th><th>$BIC$信息量</th></tr></thead><tbody><tr><td>最大值0.9951031</td><td>最小值2.490471</td><td>最小值-102.93685</td></tr><tr><td>$x_1,x_2,x_5$</td><td>$x_1,x_2,x_5$</td><td>$x_1,x_2,x_5$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>前进法</th><th>后退法</th><th>逐步回归法</th></tr></thead><tbody><tr><td>$x_1,x_2,x_5$</td><td>$x_1,x_2,x_5$</td><td>$x_1,x_2,x_5$</td></tr><tr><td>$R^2$=0.9958</td><td>$R^2$=0.9958</td><td>$R^2$=0.9958</td></tr><tr><td>$ R^2_\alpha$=0.9951</td><td>$ R^2_\alpha$=0.9951</td><td>$ R^2_\alpha$=0.9951</td></tr></tbody></table></div><p><strong>综上，最优子集为$x_1,x_2,x_5$，最优回归模型为$\hat{y}=874.60731-0.61119x_1-0.35306x_2+0.63672x_5$。</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>R语言 自变量选择 所有子集回归 逐步回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决Hexo框架博客引用图片失败的问题</title>
    <link href="/2020/11/17/%E8%A7%A3%E5%86%B3Hexo%E6%A1%86%E6%9E%B6%E5%8D%9A%E5%AE%A2%E5%BC%95%E7%94%A8%E5%9B%BE%E7%89%87%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2020/11/17/%E8%A7%A3%E5%86%B3Hexo%E6%A1%86%E6%9E%B6%E5%8D%9A%E5%AE%A2%E5%BC%95%E7%94%A8%E5%9B%BE%E7%89%87%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="解决Hexo框架博客引用图片失败的问题"><a href="#解决Hexo框架博客引用图片失败的问题" class="headerlink" title="解决Hexo框架博客引用图片失败的问题"></a>解决Hexo框架博客引用图片失败的问题</h1><h3 id="1-插件安装与配置"><a href="#1-插件安装与配置" class="headerlink" title="1.插件安装与配置"></a>1.插件安装与配置</h3><p><strong>（1）打开cmd命令行键入以下内容：</strong></p><pre><code class="hljs php">npm install -g cnpm --registry=https:<span class="hljs-comment">//registry.npm.taobao.org  #载入镜像源</span>cnpm install https:<span class="hljs-comment">//github.com/CodeFalling/hexo-asset-image --save  #安装插件hexo-asset-image</span></code></pre><p><strong>（2）用记事本打开/node_modules/hexo-asset-image/index.js，将内容替换为如下代码：</strong></p><pre><code class="hljs javascript"><span class="hljs-meta">&#x27;use strict&#x27;</span>;<span class="hljs-keyword">var</span> cheerio = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;cheerio&#x27;</span>);<span class="hljs-comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getPosition</span>(<span class="hljs-params">str, m, i</span>) </span>&#123;  <span class="hljs-keyword">return</span> str.split(m, i).join(m).length;&#125;<span class="hljs-keyword">var</span> version = <span class="hljs-built_in">String</span>(hexo.version).split(<span class="hljs-string">&#x27;.&#x27;</span>);hexo.extend.filter.register(<span class="hljs-string">&#x27;after_post_render&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;  <span class="hljs-keyword">var</span> config = hexo.config;  <span class="hljs-function"><span class="hljs-title">if</span>(<span class="hljs-params">config.post_asset_folder</span>)</span>&#123;     <span class="hljs-keyword">var</span> link = data.permalink; <span class="hljs-keyword">if</span>(version.length &gt; <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">Number</span>(version[<span class="hljs-number">0</span>]) == <span class="hljs-number">3</span>)    <span class="hljs-keyword">var</span> beginPos = getPosition(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>; <span class="hljs-keyword">else</span>    <span class="hljs-keyword">var</span> beginPos = getPosition(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">3</span>) + <span class="hljs-number">1</span>; <span class="hljs-comment">// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span> <span class="hljs-keyword">var</span> endPos = link.lastIndexOf(<span class="hljs-string">&#x27;/&#x27;</span>) + <span class="hljs-number">1</span>;    link = link.substring(beginPos, endPos);    <span class="hljs-keyword">var</span> toprocess = [<span class="hljs-string">&#x27;excerpt&#x27;</span>, <span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>];    <span class="hljs-function"><span class="hljs-title">for</span>(<span class="hljs-params"><span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; toprocess.length; i++</span>)</span>&#123;      <span class="hljs-keyword">var</span> key = toprocess[i];       <span class="hljs-keyword">var</span> $ = cheerio.load(data[key], &#123;        ignoreWhitespace: <span class="hljs-literal">false</span>,        xmlMode: <span class="hljs-literal">false</span>,        lowerCaseTags: <span class="hljs-literal">false</span>,        decodeEntities: <span class="hljs-literal">false</span>      &#125;);      $(<span class="hljs-string">&#x27;img&#x27;</span>).each(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;  <span class="hljs-keyword">if</span> ($(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>))&#123;   <span class="hljs-comment">// For windows style path, we replace &#x27;\&#x27; to &#x27;/&#x27;.</span>   <span class="hljs-keyword">var</span> src = $(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>).replace(<span class="hljs-string">&#x27;\\&#x27;</span>, <span class="hljs-string">&#x27;/&#x27;</span>);   <span class="hljs-keyword">if</span>(!<span class="hljs-regexp">/http[s]*.*|\/\/.*/</span>.test(src) &amp;&amp;      !<span class="hljs-regexp">/^\s*\//</span>.test(src)) &#123;     <span class="hljs-comment">// For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed.</span>     <span class="hljs-comment">// In addition, to support multi-level local directory.</span>     <span class="hljs-keyword">var</span> linkArray = link.split(<span class="hljs-string">&#x27;/&#x27;</span>).filter(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)</span>&#123;    <span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span>;     &#125;);     <span class="hljs-keyword">var</span> srcArray = src.split(<span class="hljs-string">&#x27;/&#x27;</span>).filter(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)</span>&#123;    <span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span> &amp;&amp; elem != <span class="hljs-string">&#x27;.&#x27;</span>;     &#125;);     <span class="hljs-keyword">if</span>(srcArray.length &gt; <span class="hljs-number">1</span>)    srcArray.shift();     src = srcArray.join(<span class="hljs-string">&#x27;/&#x27;</span>);     $(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>, config.root + link + src);     <span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info(<span class="hljs-string">&quot;update link as:--&gt;&quot;</span>+config.root + link + src);   &#125;  &#125;<span class="hljs-keyword">else</span>&#123;   <span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info(<span class="hljs-string">&quot;no src attr, skipped...&quot;</span>);   <span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info($(<span class="hljs-built_in">this</span>));  &#125;      &#125;);      data[key] = $.html();    &#125;  &#125;&#125;);</code></pre><p><strong>（3）打开blog文件夹中的_config.yml修改下述两项内容：</strong></p><pre><code class="hljs php">post_asset_folder: <span class="hljs-literal">true</span></code></pre><pre><code class="hljs php"><span class="hljs-comment"># URL</span><span class="hljs-comment">## If your site is put in a subdirectory, set url as &#x27;http://example.com/child&#x27; and root as &#x27;/child/&#x27;</span>url: http:<span class="hljs-comment">//github注册昵称.github.io</span></code></pre><h3 id="2-图片存储与引用"><a href="#2-图片存储与引用" class="headerlink" title="2.图片存储与引用"></a>2.图片存储与引用</h3><p><strong>(1)【存储】在cmd命令行键入</strong></p><pre><code class="hljs php">hexo n <span class="hljs-string">&quot;文章名&quot;</span></code></pre><div class="table-container"><table><thead><tr><th>随即在/blog/source/_posts目录下会产生：</th></tr></thead><tbody><tr><td>(i).“文章名.md“文件</td></tr><tr><td>(ii).”文章名“文件夹——将图片全部存入该文件夹内</td></tr></tbody></table></div><p><strong>(2)【图片引用】编辑.md文件时，需使用下述语句：</strong></p><pre><code class="hljs php">&#123;% asset_img 图片名.图片格式 %&#125;  <span class="hljs-comment">##举例：&#123;% asset_img thisisapicture.png %&#125;</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo 博客优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言之序列的自相关检验与处理-多元线性回归</title>
    <link href="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <url>/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1 id="习题4-14"><a href="#习题4-14" class="headerlink" title="习题4.14"></a>习题4.14</h1><h4 id="1-导入数据建立初始回归方程"><a href="#1-导入数据建立初始回归方程" class="headerlink" title="1.导入数据建立初始回归方程"></a>1.导入数据建立初始回归方程</h4><pre><code class="hljs R"><span class="hljs-comment">#导入数据</span>data4.14&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/4.14.csv&quot;</span>)data.frame(matrix(unlist(data4.14),nrow=<span class="hljs-number">52</span>))y=data4.14[[<span class="hljs-number">1</span>]]attach(data4.14)<span class="hljs-comment">#最小二乘法建立回归方程</span>lm1&lt;-lm(y~x1+x2,data=data4.14)summary(lm1)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.png" class=""><p><strong>结果分析</strong>：<strong>利用最小二乘估计建立回归模型，得到回归方程</strong></p><script type="math/tex; mode=display">\hat{y}=-574.062+191.099x1+2.045x2</script><h4 id="2-残差分析"><a href="#2-残差分析" class="headerlink" title="2.残差分析"></a>2.残差分析</h4><pre><code class="hljs R"><span class="hljs-comment">#计算残差</span>e=resid(lm1)e<span class="hljs-comment">#绘制残差散点图</span>y_hat=fitted(lm1)plot(y_hat,e,ylim=<span class="hljs-built_in">c</span>(-<span class="hljs-number">800</span>,<span class="hljs-number">800</span>))abline(h=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),lty=<span class="hljs-number">5</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/2.png" class=""><h4 id="3-自相关检验"><a href="#3-自相关检验" class="headerlink" title="3.自相关检验"></a>3.自相关检验</h4><h5 id="3-1图检验-定性"><a href="#3-1图检验-定性" class="headerlink" title="3.1图检验(定性)"></a>3.1图检验(定性)</h5><pre><code class="hljs R"><span class="hljs-comment">#自相关检验</span><span class="hljs-comment">#1.图检验</span>n=<span class="hljs-built_in">length</span>(e)e_i=e[<span class="hljs-built_in">c</span>(<span class="hljs-number">2</span>:n)]e_i_1=e[<span class="hljs-built_in">c</span>(<span class="hljs-number">1</span>:n-<span class="hljs-number">1</span>)]plot(e_i_1,e_i,ylim=<span class="hljs-built_in">c</span>(-<span class="hljs-number">800</span>,<span class="hljs-number">800</span>))abline(h=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),v=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),lty=<span class="hljs-number">5</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/3.png" class=""><h5 id="3-2DW检验-定量"><a href="#3-2DW检验-定量" class="headerlink" title="3.2DW检验(定量)"></a>3.2DW检验(定量)</h5><pre><code class="hljs R"><span class="hljs-comment">#2.DW检验</span><span class="hljs-comment">#（1）法1：</span>library(lmtest)dwtest(lm1,alternative=<span class="hljs-string">&quot;two.sided&quot;</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/4.png" class=""><pre><code class="hljs R"><span class="hljs-comment">#（2）法2：</span>library(car)dw=durbinWatsonTest(lm1)dwrho_hat=dw[[<span class="hljs-number">1</span>]]dw_value=dw[[<span class="hljs-number">2</span>]]</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/5.png" class=""><p><strong>结果分析：</strong> </p><div class="table-container"><table><thead><tr><th>——定性（图检验）</th></tr></thead><tbody><tr><td>a. 残差散点图：以自变量x为横轴，残差e为纵轴，绘制残差散点图，可发现点的分布具有规律性，随着拟合值y^的增大逐渐靠近x=0，故可推测残差序列可能在一定程度上具有趋势性，随机误差项存在自相关。</td></tr><tr><td>b. 残差自相关图：以e(i-1)为横轴，e(i)为纵轴，绘制残差e的自相关图，可以发现，点主要分布在1和3象限，具有趋势性，故基本可以认定随机误差项存在正自相关性。</td></tr><tr><td><strong>——定量（利用DW统计量判断序列的自相关性）</strong></td></tr><tr><td>由输出结果可知，p_value&lt;0.05，故序列存在明显的自相关性。</td></tr></tbody></table></div><h4 id="4-处理序列自相关"><a href="#4-处理序列自相关" class="headerlink" title="4.处理序列自相关"></a>4.处理序列自相关</h4><h5 id="4-1迭代法"><a href="#4-1迭代法" class="headerlink" title="4.1迭代法"></a>4.1迭代法</h5><pre><code class="hljs R"><span class="hljs-comment">#处理序列相关</span><span class="hljs-comment">#1.迭代法</span><span class="hljs-comment">#初始化重要参数</span>y_new=yx1_new=x1x2_new=x2len=<span class="hljs-built_in">length</span>(y_new)iter=<span class="hljs-number">0</span><span class="hljs-comment">#迭代次数</span>j=<span class="hljs-number">0</span><span class="hljs-comment">#结果list索引</span>dw_critical_value=dw_critical(n=len,k=<span class="hljs-number">3</span>)dL_value=dw_critical_value[[<span class="hljs-number">1</span>]][<span class="hljs-number">1</span>]dU_value=dw_critical_value[[<span class="hljs-number">2</span>]][<span class="hljs-number">1</span>]dU__value=dw_critical_value[[<span class="hljs-number">3</span>]][<span class="hljs-number">1</span>]dL__value=dw_critical_value[[<span class="hljs-number">4</span>]][<span class="hljs-number">1</span>]result=vector(mode=<span class="hljs-string">&quot;list&quot;</span>)<span class="hljs-comment">#存储结果</span><span class="hljs-comment">#开始循环迭代，直至某次迭代中模型的DW值落于确定无自相关的区域</span><span class="hljs-keyword">while</span>(dw_value&lt;dU_value||dw_value&gt;dU__value)&#123;  <span class="hljs-comment">#更新数据，建模</span>  dw_value&lt;dU_value||dw_value&gt;dU__value  y_new=y_new[<span class="hljs-number">2</span>:len]-rho_hat*y_new[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]  x1_new=x1_new[<span class="hljs-number">2</span>:len]-rho_hat*x1_new[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]  x2_new=x2_new[<span class="hljs-number">2</span>:len]-rho_hat*x2_new[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]  lm_new=lm(y_new~x1_new+x2_new)      <span class="hljs-comment">#DW检验得到DW值和rho_hat值</span>  dw_new=durbinWatsonTest(lm_new)  rho_hat=dw_new[[<span class="hljs-number">1</span>]]  dw_value=dw_new[[<span class="hljs-number">2</span>]]      <span class="hljs-comment">#更新参数</span>  len=len-<span class="hljs-number">1</span>  dw_critical_value=dw_critical(n=len,k=<span class="hljs-number">3</span>)  dL_value=dw_critical_value[[<span class="hljs-number">1</span>]][<span class="hljs-number">1</span>]  dU_value=dw_critical_value[[<span class="hljs-number">2</span>]][<span class="hljs-number">1</span>]  dU__value=dw_critical_value[[<span class="hljs-number">3</span>]][<span class="hljs-number">1</span>]  dL__value=dw_critical_value[[<span class="hljs-number">4</span>]][<span class="hljs-number">1</span>]      <span class="hljs-comment">#将DW值落于不确定和确定无自相关的模型结果存储，以便后期根据模型拟合优度进行选择</span>  <span class="hljs-keyword">if</span>(dw_value&gt;dL_value&amp;&amp;dw_value&lt;dL__value)&#123;    j=j+<span class="hljs-number">1</span>    result[[j]]=summary(lm_new)  &#125;  <span class="hljs-comment">#迭代</span>  iter=iter+<span class="hljs-number">1</span>&#125;resultiterdw_value</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/6.png" class=""><p><strong>结果分析：</strong></p><div class="table-container"><table><thead><tr><th>一次迭代</th></tr></thead><tbody><tr><td>DW统计量落入无自相关区域</td></tr><tr><td>残差标准差258&lt;原始方程残差标准差329.7</td></tr><tr><td>通过F检验</td></tr><tr><td>拟合优度R方值/调整后的R方值=0.9938/0.9935</td></tr></tbody></table></div><h5 id="4-2差分法"><a href="#4-2差分法" class="headerlink" title="4.2差分法"></a>4.2差分法</h5><pre><code class="hljs R"><span class="hljs-comment">#2.一阶差分</span>len=<span class="hljs-built_in">length</span>(y)dy=y[<span class="hljs-number">2</span>:len]-y[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]dx1=diff(x1)<span class="hljs-comment">#做差分的两种方式</span>dx2=diff(x2)lm3=lm(dy~dx1+dx2)summary(lm3)<span class="hljs-comment">#DW检验</span>dwtest(lm3,alternative=<span class="hljs-string">&#x27;two.sided&#x27;</span>)dw_critical(n=len,k=<span class="hljs-number">3</span>)detach(data4.14)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/7.png" class=""><h4 id="5-各回归模型的优良性对比"><a href="#5-各回归模型的优良性对比" class="headerlink" title="5.各回归模型的优良性对比"></a>5.各回归模型的优良性对比</h4><div class="table-container"><table><thead><tr><th>原始回归模型</th><th>一次迭代</th><th>差分</th></tr></thead><tbody><tr><td>正自相关</td><td>无自相关</td><td>无自相关</td></tr><tr><td>显著通过F检验</td><td>显著通过F检验</td><td>显著通过F检验</td></tr><tr><td>残差标准差329.7</td><td>258</td><td>283.8</td></tr><tr><td>拟合优度R方值/调整后的R方值=0.2928/0.264</td><td>0.4704/0.4483</td><td>0.5106/0.4902</td></tr><tr><td>DW统计量0.745</td><td>1.696</td><td>2.042</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>结果分析</th></tr></thead><tbody><tr><td>处理序列自相关问题上，差分法最为简便，且自相关性消除得最为彻底，DW统计量较之迭代法，更接近2。与此同时，从R方值和残差标准差来看，差分后模型的拟合优度最佳。</td></tr></tbody></table></div>]]></content>
    
    
    
    <tags>
      
      <tag>应用回归分析 R语言 DW检验</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言之序列的自相关检验与处理-一元线性回归</title>
    <link href="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <url>/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1 id="习题4-13"><a href="#习题4-13" class="headerlink" title="习题4.13"></a>习题4.13</h1><h4 id="0-编写查取DW检验上下界的函数"><a href="#0-编写查取DW检验上下界的函数" class="headerlink" title="0.编写查取DW检验上下界的函数"></a>0.编写查取DW检验上下界的函数</h4><pre><code class="hljs R"><span class="hljs-comment">#由于r中不能查取DW检验上下界，故首先编写函数</span><span class="hljs-comment">#导入DW检验上下界表</span><span class="hljs-comment">#根据4.13和4.14题目的需求，只导入表中部分内容，并对部分缺失值进行了填补</span><span class="hljs-comment">#此处观测值数目取15-55，解释变量数目为2，3</span>K2&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/dw_k2.csv&quot;</span>)K3&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/dw_k3.csv&quot;</span>)K2$N=<span class="hljs-built_in">c</span>(<span class="hljs-number">15</span>:<span class="hljs-number">55</span>)K3$N=<span class="hljs-built_in">c</span>(<span class="hljs-number">15</span>:<span class="hljs-number">55</span>)dw_list=<span class="hljs-built_in">list</span>(K2,K3)dw_list<span class="hljs-comment">#调取观测值数目n，解释变量数目为k的对应dL和dU值</span>dw_critical&lt;-<span class="hljs-keyword">function</span>(n,k)&#123; dL=dw_list[[k-<span class="hljs-number">1</span>]][n-<span class="hljs-number">14</span>,<span class="hljs-number">1</span>] dU=dw_list[[k-<span class="hljs-number">1</span>]][n-<span class="hljs-number">14</span>,<span class="hljs-number">2</span>] dL_=<span class="hljs-number">4</span>-dL dU_=<span class="hljs-number">4</span>-dU print(data.frame(dL,dU,dU_,dL_))          &#125;<span class="hljs-comment">#测试函数效果</span>dw_critical(n=<span class="hljs-number">15</span>,k=<span class="hljs-number">2</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.png" class=""><h4 id="1-导入数据建立初始回归方程"><a href="#1-导入数据建立初始回归方程" class="headerlink" title="1.导入数据建立初始回归方程"></a>1.导入数据建立初始回归方程</h4><pre><code class="hljs R"><span class="hljs-comment">#导入数据</span>data4.13&lt;-read.csv(<span class="hljs-string">&quot;C:/Users/DELL/Desktop/4.13.csv&quot;</span>)attach(data4.13)<span class="hljs-comment">#最小二乘法建立回归方程</span>lm1&lt;-lm(y~x,data=data4.13)summary(lm1)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/2.png" class=""><p><strong>结果分析</strong>：<strong>利用最小二乘估计建立回归模型，得到回归方程</strong></p><script type="math/tex; mode=display">\hat{y}=-1.435+0.176x</script><h4 id="2-残差分析"><a href="#2-残差分析" class="headerlink" title="2.残差分析"></a>2.残差分析</h4><pre><code class="hljs R"><span class="hljs-comment">#计算残差</span>e=resid(lm1)<span class="hljs-comment">#绘制残差散点图</span>plot(data4.13$x,e,ylim=<span class="hljs-built_in">c</span>(-<span class="hljs-number">0.2</span>,<span class="hljs-number">0.2</span>))abline(h=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),lty=<span class="hljs-number">5</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/3.png" class=""><h4 id="3-自相关检验"><a href="#3-自相关检验" class="headerlink" title="3.自相关检验"></a>3.自相关检验</h4><h5 id="3-1图检验-定性"><a href="#3-1图检验-定性" class="headerlink" title="3.1图检验(定性)"></a>3.1图检验(定性)</h5><pre><code class="hljs R"><span class="hljs-comment">#自相关检验</span><span class="hljs-comment">#1.图检验</span>n=<span class="hljs-built_in">length</span>(e)e_i=e[<span class="hljs-built_in">c</span>(<span class="hljs-number">2</span>:n)]e_i_1=e[<span class="hljs-built_in">c</span>(<span class="hljs-number">1</span>:n-<span class="hljs-number">1</span>)]plot(e_i_1,e_i,ylim=<span class="hljs-built_in">c</span>(-<span class="hljs-number">0.3</span>,<span class="hljs-number">0.3</span>))abline(h=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),v=<span class="hljs-built_in">c</span>(<span class="hljs-number">0</span>),lty=<span class="hljs-number">5</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/4.png" class=""><h5 id="3-2DW检验-定量"><a href="#3-2DW检验-定量" class="headerlink" title="3.2DW检验(定量)"></a>3.2DW检验(定量)</h5><pre><code class="hljs R"><span class="hljs-comment">#2.DW检验</span><span class="hljs-comment">#（1）法1：</span>library(lmtest)dwtest(lm1,alternative=<span class="hljs-string">&quot;two.sided&quot;</span>)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/5.png" class=""><pre><code class="hljs R"><span class="hljs-comment">#（2）法2：</span>library(car)dw=durbinWatsonTest(lm1)dwrho_hat=dw[[<span class="hljs-number">1</span>]]dw_value=dw[[<span class="hljs-number">2</span>]]</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/6.png" class=""><p><strong>结果分析：</strong> </p><div class="table-container"><table><thead><tr><th>——定性（图检验）</th></tr></thead><tbody><tr><td>a. 残差散点图：以自变量x为横轴，残差e为纵轴，绘制残差散点图，可发现点的分布具有规律性，形似“M”，故可推测残差序列可能在一定程度上具有周期性，随机误差项存在自相关。</td></tr><tr><td>b. 残差自相关图：以e(i-1)为横轴，e(i)为纵轴，绘制残差e的自相关图，可以发现，点主要分布在1和3象限，具有趋势性，故基本可以认定随机误差项存在正自相关性。</td></tr><tr><td><strong>——定量（利用DW统计量判断序列的自相关性）</strong></td></tr><tr><td>由输出结果可知，p_value&lt;0.05，故序列存在明显的自相关性。</td></tr></tbody></table></div><h4 id="4-处理序列自相关"><a href="#4-处理序列自相关" class="headerlink" title="4.处理序列自相关"></a>4.处理序列自相关</h4><h5 id="4-1迭代法"><a href="#4-1迭代法" class="headerlink" title="4.1迭代法"></a>4.1迭代法</h5><pre><code class="hljs R"><span class="hljs-comment">#处理序列相关</span><span class="hljs-comment">#1.迭代法</span><span class="hljs-comment">#初始化重要参数</span>y_new=data4.13$yx_new=data4.13$xlen=<span class="hljs-built_in">length</span>(y_new)iter=<span class="hljs-number">0</span><span class="hljs-comment">#迭代次数</span>j=<span class="hljs-number">0</span><span class="hljs-comment">#结果list索引</span>dw_critical_value=dw_critical(n=len,k=<span class="hljs-number">2</span>)dL_value=dw_critical_value[[<span class="hljs-number">1</span>]][<span class="hljs-number">1</span>]dU_value=dw_critical_value[[<span class="hljs-number">2</span>]][<span class="hljs-number">1</span>]dU__value=dw_critical_value[[<span class="hljs-number">3</span>]][<span class="hljs-number">1</span>]dL__value=dw_critical_value[[<span class="hljs-number">4</span>]][<span class="hljs-number">1</span>]result=vector(mode=<span class="hljs-string">&quot;list&quot;</span>)<span class="hljs-comment">#存储结果</span><span class="hljs-comment">#开始循环迭代，直至某次迭代中模型的DW值落于确定无自相关的区域</span><span class="hljs-keyword">while</span>(dw_value&lt;dU_value||dw_value&gt;dU__value)&#123;  <span class="hljs-comment">#更新数据，建模</span>  dw_value&lt;dU_value||dw_value&gt;dU__value  y_new=y_new[<span class="hljs-number">2</span>:len]-rho_hat*y_new[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]  x_new=x_new[<span class="hljs-number">2</span>:len]-rho_hat*x_new[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]  lm_new=lm(y_new~x_new)      <span class="hljs-comment">#DW检验得到DW值和rho_hat值</span>  dw_new=durbinWatsonTest(lm_new)  rho_hat=dw_new[[<span class="hljs-number">1</span>]]  dw_value=dw_new[[<span class="hljs-number">2</span>]]      <span class="hljs-comment">#更新参数</span>  len=len-<span class="hljs-number">1</span>  dw_critical_value=dw_critical(n=len,k=<span class="hljs-number">2</span>)  dL_value=dw_critical_value[[<span class="hljs-number">1</span>]][<span class="hljs-number">1</span>]  dU_value=dw_critical_value[[<span class="hljs-number">2</span>]][<span class="hljs-number">1</span>]  dU__value=dw_critical_value[[<span class="hljs-number">3</span>]][<span class="hljs-number">1</span>]  dL__value=dw_critical_value[[<span class="hljs-number">4</span>]][<span class="hljs-number">1</span>]      <span class="hljs-comment">#将DW值落于不确定和确定无自相关的模型结果存储，以便后期根据模型拟合优度进行选择</span>  <span class="hljs-keyword">if</span>(dw_value&gt;dL_value&amp;&amp;dw_value&lt;dL__value)&#123;    j=j+<span class="hljs-number">1</span>    result[[j]]=summary(lm_new)  &#125;  <span class="hljs-comment">#迭代</span>  iter=iter+<span class="hljs-number">1</span>&#125;resultiter</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/7.png" class=""><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/8.png" class=""><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/9.png" class=""><p><strong>结果分析：</strong></p><div class="table-container"><table><thead><tr><th>算法分析：</th></tr></thead><tbody><tr><td>1.由于循环条件为：<strong>模型的DW统计量未落入无自相关区域</strong>，故由迭代次数为2可知，进行两次迭代操作后的最终模型，其随机误差项满足无自相关。</td></tr><tr><td>2.由于把每次循环后的模型总结，存储入result中的条件为：<strong>模型的DW统计量落入不确定自相关和确定无自相关区域</strong>，故由result返回的结果可知，一次迭代后的模型DW统计量落入不确定自相关的区域。</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>一次迭代</th><th>二次迭代</th></tr></thead><tbody><tr><td>DW统计量落入不确定自相关区域</td><td>DW统计量未落入无自相关区域</td></tr><tr><td>残差标准差0.073&lt;原始方程残差标准差0.9744</td><td>残差标准差0.686&lt;0.073&lt;0.9744</td></tr><tr><td>通过F检验</td><td>通过F检验</td></tr><tr><td>拟合优度R方值/调整后的R方值=0.9938/0.9935</td><td>拟合优度R方值/调整后的R方值=0.9905/0.9899</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>综合结果分析：</th></tr></thead><tbody><tr><td>由上述两条结论可知，result中返回的两个模型——一次迭代和二次迭代，都一定程度上消除了随机误差项的自相关性。因此，需要综合考量模型拟合优度，是否通过显著性检验等，做出最优选择。其中，在全部通过检验的情况下，一次迭代的拟合优度值更高，在模型尽可能简化的原则下，应优选一次迭代的模型。</td></tr></tbody></table></div><h5 id="4-2差分法"><a href="#4-2差分法" class="headerlink" title="4.2差分法"></a>4.2差分法</h5><pre><code class="hljs R"><span class="hljs-comment">#2.一阶差分</span>len=<span class="hljs-built_in">length</span>(data4.13$y)dy=data4.13$y[<span class="hljs-number">2</span>:len]-data4.13$y[<span class="hljs-number">1</span>:len-<span class="hljs-number">1</span>]dx=diff(data4.13$x)<span class="hljs-comment">#做差分的两种方式</span>lm3=lm(dy~dx)summary(lm3)<span class="hljs-comment">#DW检验</span>dwtest(lm3,alternative=<span class="hljs-string">&#x27;two.sided&#x27;</span>)dw_critical(n=len,k=<span class="hljs-number">2</span>)detach(data4.13)</code></pre><img src="/2020/11/17/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%BA%8F%E5%88%97%E7%9A%84%E8%87%AA%E7%9B%B8%E5%85%B3%E6%A3%80%E9%AA%8C%E4%B8%8E%E5%A4%84%E7%90%86-%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/10.png" class=""><h4 id="5-各回归模型的优良性对比"><a href="#5-各回归模型的优良性对比" class="headerlink" title="5.各回归模型的优良性对比"></a>5.各回归模型的优良性对比</h4><div class="table-container"><table><thead><tr><th>原始回归模型</th><th>一次迭代</th><th>二次迭代</th><th>差分</th></tr></thead><tbody><tr><td>正自相关</td><td>不确定自相关</td><td>无自相关</td><td>无自相关</td></tr><tr><td>显著通过F检验、t检验</td><td>显著通过F检验</td><td>显著通过F检验</td><td>显著通过F检验</td></tr><tr><td>残差标准差0.9744</td><td>0.073</td><td>0.068</td><td>0.074</td></tr><tr><td>拟合优度R方值/调整后的R方值=0.9985/0.9984</td><td>0.9938/0.9935</td><td>0.9905/0.9899</td><td>0.9573/0.9548</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>结果分析</th></tr></thead><tbody><tr><td>1.原始回归模型拟合效果最优。</td></tr><tr><td>2.处理序列自相关问题上，差分法最为简便，一次差分即可将自相关性消除得很彻底。但从R方值和残差标准差来看，模型的拟合优度逊于迭代法。</td></tr></tbody></table></div>]]></content>
    
    
    
    <tags>
      
      <tag>应用回归分析 R语言 DW检验</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>搭建个人博客（Hexo框架）</title>
    <link href="/2020/11/13/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88Hexo%E6%A1%86%E6%9E%B6%EF%BC%89/"/>
    <url>/2020/11/13/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88Hexo%E6%A1%86%E6%9E%B6%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="搭建个人博客-Hexo博客框架"><a href="#搭建个人博客-Hexo博客框架" class="headerlink" title="搭建个人博客(Hexo博客框架)"></a>搭建个人博客(Hexo博客框架)</h1><h3 id="1-环境搭建"><a href="#1-环境搭建" class="headerlink" title="1.环境搭建"></a>1.环境搭建</h3><h5 id="下载node-js网址：https-nodejs-org-en-（内含npm【包管理器】和node）"><a href="#下载node-js网址：https-nodejs-org-en-（内含npm【包管理器】和node）" class="headerlink" title="下载node.js网址：https://nodejs.org/en/（内含npm【包管理器】和node）"></a>下载node.js网址：<a href="https://nodejs.org/en/（内含npm【包管理器】和node）">https://nodejs.org/en/（内含npm【包管理器】和node）</a></h5><h5 id="下载git网址：https-git-scm-com-downloads"><a href="#下载git网址：https-git-scm-com-downloads" class="headerlink" title="下载git网址：https://git-scm.com/downloads"></a>下载git网址：<a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a></h5><pre><code class="hljs php"><span class="hljs-comment">#以管理员身份运行命令行cmd</span><span class="hljs-comment">#安装测试：cmd命令行分别键入“node -v”“npm -v”“git -v&quot;查看版本</span><span class="hljs-comment">#全局安装镜像源指向淘宝</span>npm install -g cnpm --registry=https:<span class="hljs-comment">//registry.npm.taobao.org</span>cnpm -v<span class="hljs-comment">#利用cnpm安装hexo框架</span>cnpm install -g hexo-clihexo -v</code></pre><h3 id="2-创建博客"><a href="#2-创建博客" class="headerlink" title="2.创建博客"></a>2.创建博客</h3><h5 id="下载markdown文本编辑器typora网址：https-typora-io"><a href="#下载markdown文本编辑器typora网址：https-typora-io" class="headerlink" title="下载markdown文本编辑器typora网址：https://typora.io/"></a>下载markdown文本编辑器typora网址：<a href="https://typora.io/">https://typora.io/</a></h5><pre><code class="hljs php">mkdir blog  <span class="hljs-comment">#在指定文件夹中创建新文件夹blog</span>cd blog\  <span class="hljs-comment">#进入文件夹</span>    <span class="hljs-comment">##注意，文件夹创建完毕后，后续所有代码操作均在该文件夹中进行</span></code></pre><pre><code class="hljs php">hexo init  <span class="hljs-comment">#初始化博客</span>hexo s  <span class="hljs-comment">#启动博客</span><span class="hljs-comment">##此时博客已在localhost:4000创建，可到浏览器中查看</span></code></pre><h4 id="2-1创建博文"><a href="#2-1创建博文" class="headerlink" title="2.1创建博文"></a>2.1创建博文</h4><pre><code class="hljs php">hexo n <span class="hljs-string">&quot;文章名&quot;</span>  <span class="hljs-comment">#然后到blog文件夹下source—&gt;_posts中查看新创建的.md文件，用typora打开并进行编辑</span>hexo clean <span class="hljs-comment">#清空</span>hexo g <span class="hljs-comment">#生成</span>hexo s <span class="hljs-comment">#重启，然后到用浏览器搜索localhost:4000进行预览</span>ctrl+c <span class="hljs-comment">#退出</span></code></pre><h3 id="3-远端部署至GitHub"><a href="#3-远端部署至GitHub" class="headerlink" title="3.远端部署至GitHub"></a>3.远端部署至GitHub</h3><h5 id="（1）登录GitHub-https-github-com-gt-创建new-repository"><a href="#（1）登录GitHub-https-github-com-gt-创建new-repository" class="headerlink" title="（1）登录GitHub(https://github.com/)-&gt;创建new repository"></a>（1）登录GitHub(<a href="https://github.com/)-&gt;创建new">https://github.com/)-&gt;创建new</a> repository</h5><h5 id="（2）在命令行cmd中安装插件"><a href="#（2）在命令行cmd中安装插件" class="headerlink" title="（2）在命令行cmd中安装插件"></a>（2）在命令行cmd中安装插件</h5><pre><code class="hljs php">cnpm install --save hexo-deployer-git <span class="hljs-comment">#下载安装插件</span></code></pre><h5 id="（3）使用记事本打开blog文件夹中的config-yml修改配置如下："><a href="#（3）使用记事本打开blog文件夹中的config-yml修改配置如下：" class="headerlink" title="（3）使用记事本打开blog文件夹中的config.yml修改配置如下："></a>（3）使用记事本打开blog文件夹中的config.yml修改配置如下：</h5><pre><code class="hljs php">deploy:  type: <span class="hljs-string">&#x27;git&#x27;</span>  repo: https:<span class="hljs-comment">//github.com/YufeiPang/YufeiPang.github.io #此处为GitHub上创建的仓库的地址</span>  branch: master  <span class="hljs-comment">##注意，冒号后如丢失空格，会导致失败</span></code></pre><h5 id="（4）回到命令行cmd向远端部署，代码如下："><a href="#（4）回到命令行cmd向远端部署，代码如下：" class="headerlink" title="（4）回到命令行cmd向远端部署，代码如下："></a>（4）回到命令行cmd向远端部署，代码如下：</h5><pre><code class="hljs php">git config --<span class="hljs-keyword">global</span> user.email <span class="hljs-string">&quot;you@example.com&quot;</span>  <span class="hljs-comment">#在&quot;&quot;内输入GitHub注册邮箱地址</span>git config --<span class="hljs-keyword">global</span> user.name <span class="hljs-string">&quot;Your Name&quot;</span>  <span class="hljs-comment">#在&quot;&quot;内输入GitHub注册昵称</span>hexo d  <span class="hljs-comment">#向远端部署</span></code></pre><h5 id="（5）再次刷新查看GitHub仓库，此后则可以通过仓库名”注册昵称-github-io“访问博客"><a href="#（5）再次刷新查看GitHub仓库，此后则可以通过仓库名”注册昵称-github-io“访问博客" class="headerlink" title="（5）再次刷新查看GitHub仓库，此后则可以通过仓库名”注册昵称.github.io“访问博客"></a>（5）再次刷新查看GitHub仓库，此后则可以通过仓库名”注册昵称.github.io“访问博客</h5><h3 id="4-更换主题"><a href="#4-更换主题" class="headerlink" title="4.更换主题"></a>4.更换主题</h3><p>此处使用yilia主题做示范</p><h5 id="（1）在命令行cmd中下载主题yilia"><a href="#（1）在命令行cmd中下载主题yilia" class="headerlink" title="（1）在命令行cmd中下载主题yilia"></a>（1）在命令行cmd中下载主题yilia</h5><pre><code class="hljs php">git <span class="hljs-keyword">clone</span> https:<span class="hljs-comment">//github.com/litten/hexo-theme-yilia.git themes/yilia  #yilia下载安装</span></code></pre><h5 id="（2）再次修改配置-config-yml"><a href="#（2）再次修改配置-config-yml" class="headerlink" title="（2）再次修改配置_config.yml"></a>（2）再次修改配置_config.yml</h5><pre><code class="hljs php">themes：yilia  <span class="hljs-comment">##注意，冒号后如丢失空格，会导致失败</span></code></pre><h5 id="（3）再次重复流程”清除界面——生成网页——重启预览——向远端部署“"><a href="#（3）再次重复流程”清除界面——生成网页——重启预览——向远端部署“" class="headerlink" title="（3）再次重复流程”清除界面——生成网页——重启预览——向远端部署“"></a>（3）再次重复流程”清除界面——生成网页——重启预览——向远端部署“</h5><pre><code class="hljs php">hexo clean  <span class="hljs-comment">#清除界面</span>hexo g  <span class="hljs-comment">#生成网页</span>hexo s  <span class="hljs-comment">#重启预览</span>hexo d  <span class="hljs-comment">#向远端部署</span><span class="hljs-comment">##注意重启预览往往对应localhost:4000本地网页，只有向远端部署后，才能利用远端网址打开博客。</span><span class="hljs-comment">##主题更新可能有延迟，可稍作等待。或多次刷新Github仓库，再利用远端网址打开博客。</span></code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/11/13/hello-world/"/>
    <url>/2020/11/13/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
